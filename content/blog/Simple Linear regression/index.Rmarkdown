---
title: "Simple Linear Regression"
subtitle: ""
excerpt: "Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. Its main goal is to find the best-fitting linear equation that can predict the dependent variable based on the independent variables."
date: 2024-09-24
author: "Kelvin Kiprono"
draft: false
# layout options: single, single-sidebar
layout: single
categories:
- R Data Analysis
---
Simple Linear Regression: Involves one independent variable and one dependent variable, modeled as:

𝑦=𝛽0 +𝛽1𝑥+𝜖

where :

- y is the dependent variable, 

- x is the independent variable, 

- 𝛽0 is the intercept, 

- β 1 is the slope, and 

- ϵ is the error term.

## Assumptions

- Linearity: The relationship between the dependent and independent variables should be linear.
- Independence: Observations should be independent of each other.
- Homoscedasticity: The variance of error terms should be constant across all levels of the - independent variable.
- Normality: The residuals (errors) should be normally distributed.

## Basic Simple Linear Regression
```{r}
# Load necessary data or generate sample data
x <- c(10, 20, 30, 40, 50)
y <- c(15, 30, 45, 50, 65)
```
## Fit the linear regression model
```{r}
model <- lm(y ~ x)
```

## View the summary to understand model performance

```{r}
summary(model)
```

## Plot and add regression line
```{r}
plot(x, y, main = "Regression Example", xlab = "X values", ylab = "Y values", pch = 16)
abline(model, col = "red", lwd = 2)
```

## Predict new values
```{r}
new_data <- data.frame(x = c(25, 35))
predictions <- predict(model, newdata = new_data)
print(predictions)
```




